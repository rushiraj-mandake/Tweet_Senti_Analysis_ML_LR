{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a45b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Sp1786/multiclass-sentiment-analysis-dataset\")\n",
    "df = dataset['train'].to_pandas()\n",
    "dftest=pd.DataFrame(dataset['test'])\n",
    "dfval=pd.DataFrame(dataset['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac3292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                               text  label sentiment\n",
      "0   9536                    Cooking microwave pizzas, yummy      2  positive\n",
      "1   6135  Any plans of allowing sub tasks to show up in ...      1   neutral\n",
      "2  17697   I love the humor, I just reworded it. Like sa...      2  positive\n",
      "3  14182                       naw idk what ur talkin about      1   neutral\n",
      "4  17840          That sucks to hear. I hate days like that      0  negative\n",
      "      id                                               text  label sentiment\n",
      "0   9235                         getting cds ready for tour      1   neutral\n",
      "1  16790   MC, happy mother`s day to your mom ;).. love yah      2  positive\n",
      "2  24840  A year from now is graduation....i am pretty s...      0  negative\n",
      "3  20744              because you had chips and sale w/o me      1   neutral\n",
      "4   6414          Great for organising my work life balance      2  positive\n",
      "      id                                               text  label sentiment\n",
      "0    317  Laying in bed til workkk... Oh the life. Defin...      0  negative\n",
      "1  24292   ooohhh imma need you to get on that asap love...      2  positive\n",
      "2   3513   Thanks! I love it they have a video, so you d...      2  positive\n",
      "3   4322     I left my ipod in the car so now its all warm.      2  positive\n",
      "4   6203  Great app. Only complaint is that I'd like the...      2  positive\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(dftest.head())\n",
    "print(dfval.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1b5f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#irrelevent columns\n",
    "drop_cols = [\n",
    "    'id',\n",
    "    'sentiment'\n",
    "]\n",
    "\n",
    "df.drop(columns=drop_cols, inplace=True)\n",
    "dftest.drop(columns=drop_cols, inplace=True)\n",
    "dfval.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0f66846",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"label\":\"target\"})\n",
    "dftest = dftest.rename(columns={\"label\":\"target\"})\n",
    "dfval = dfval.rename(columns={\"label\":\"target\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5beb7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  target\n",
      "0                    Cooking microwave pizzas, yummy       2\n",
      "1  Any plans of allowing sub tasks to show up in ...       1\n",
      "2   I love the humor, I just reworded it. Like sa...       2\n",
      "3                       naw idk what ur talkin about       1\n",
      "4          That sucks to hear. I hate days like that       0\n",
      "                                                text  target\n",
      "0                         getting cds ready for tour       1\n",
      "1   MC, happy mother`s day to your mom ;).. love yah       2\n",
      "2  A year from now is graduation....i am pretty s...       0\n",
      "3              because you had chips and sale w/o me       1\n",
      "4          Great for organising my work life balance       2\n",
      "                                                text  target\n",
      "0  Laying in bed til workkk... Oh the life. Defin...       0\n",
      "1   ooohhh imma need you to get on that asap love...       2\n",
      "2   Thanks! I love it they have a video, so you d...       2\n",
      "3     I left my ipod in the car so now its all warm.       2\n",
      "4  Great app. Only complaint is that I'd like the...       2\n"
     ]
    }
   ],
   "source": [
    "print( df.head())\n",
    "print( dftest.head())\n",
    "print( dfval.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3d318a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target\"].unique()\n",
    "dftest[ \"target\"].unique()\n",
    "dfval[\"target\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7626a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"az_train_review.csv\",index = False )\n",
    "dftest.to_csv(\"az_test_review.csv\",index = False )\n",
    "dfval.to_csv(\"az_val_review.csv\",index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a83eeb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rushiraj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31232/31232 [00:00<00:00, 45696.69it/s]\n",
      "100%|██████████| 5206/5206 [00:00<00:00, 48350.34it/s]\n",
      "100%|██████████| 5205/5205 [00:00<00:00, 53015.10it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "nltk.download(\"stopwords\")\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "URL_PATTERN = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "MENTION_PATTERN = re.compile(r\"@\\w+\")\n",
    "HASHTAG_PATTERN = re.compile(r\"#(\\w+)\")\n",
    "RT_PATTERN = re.compile(r\"\\brt\\b\", re.IGNORECASE)\n",
    "NON_ALNUM_PATTERN = re.compile(r\"[^a-z0-9\\s\\.\\,\\!\\?\\']\")\n",
    "\n",
    "\n",
    "def Amazon(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    t = text.strip()\n",
    "\n",
    "    # Remove URLs and mentions\n",
    "    t = URL_PATTERN.sub(\" \", t)\n",
    "    \n",
    "    t = MENTION_PATTERN.sub(\" \", t)\n",
    "\n",
    "    # Keep hashtag words (drop '#')\n",
    "    t = HASHTAG_PATTERN.sub(r\"\\1\", t)\n",
    "\n",
    "\n",
    "    # Remove RT markers\n",
    "    t = RT_PATTERN.sub(\" \", t)\n",
    "\n",
    "    # Lowercase\n",
    "    t = t.lower()\n",
    "\n",
    "\n",
    "    # Remove special characters (keep basic punctuation)\n",
    "    t = NON_ALNUM_PATTERN.sub(\" \", t)\n",
    "\n",
    "    # Normalize whitespace\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "\n",
    "    # Remove stopwords (light)\n",
    "    tokens = [w for w in t.split() if w not in STOPWORDS]\n",
    "    t = \" \".join(tokens)\n",
    "\n",
    "    return t\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"az_train_review.csv\")\n",
    "    df[\"clean_text\"] = df[\"text\"].progress_apply(Amazon)\n",
    "if __name__ == \"__main__\":\n",
    "    df1= pd.read_csv(\"az_test_review.csv\")\n",
    "    df1[\"clean_text\"] = df1[\"text\"].progress_apply(Amazon)\n",
    "if __name__ == \"__main__\":\n",
    "    df2= pd.read_csv(\"az_val_review.csv\")\n",
    "    df2[\"clean_text\"] = df2[\"text\"].progress_apply(Amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8b0af62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: az_train_review_clean.csv Shape: (31181, 3)\n",
      "Saved: az_test_review_clean.csv Shape: (5198, 3)\n",
      "Saved: az_val_review_clean.csv Shape: (5195, 3)\n"
     ]
    }
   ],
   "source": [
    "# Drop empty rows post-cleaning\n",
    "df = df[df[\"clean_text\"].str.len() > 0].copy()\n",
    "df1 = df1[df1[\"clean_text\"].str.len() > 0].copy()\n",
    "df2 = df2[df2[\"clean_text\"].str.len() > 0].copy()\n",
    "\n",
    "\n",
    "df.to_csv(\"az_train_review_clean.csv\", index=False)\n",
    "print(\"Saved:\", \"az_train_review_clean.csv\", \"Shape:\", df.shape)\n",
    "df1.to_csv(\"az_test_review_clean.csv\", index=False)\n",
    "print(\"Saved:\", \"az_test_review_clean.csv\", \"Shape:\", df1.shape)\n",
    "df2.to_csv(\"az_val_review_clean.csv\", index=False)\n",
    "print(\"Saved:\", \"az_val_review_clean.csv\", \"Shape:\", df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb83eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"az_train_review_clean.csv\")\n",
    "test_df=pd.read_csv(\"az_test_review_clean.csv\")\n",
    "val_df=pd.read_csv(\"az_val_review_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab72c720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cooking microwave pizzas, yummy</td>\n",
       "      <td>2</td>\n",
       "      <td>cooking microwave pizzas, yummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Any plans of allowing sub tasks to show up in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>plans allowing sub tasks show widget?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love the humor, I just reworded it. Like sa...</td>\n",
       "      <td>2</td>\n",
       "      <td>love humor, reworded it. like saying 'group th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>naw idk what ur talkin about</td>\n",
       "      <td>1</td>\n",
       "      <td>naw idk ur talkin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That sucks to hear. I hate days like that</td>\n",
       "      <td>0</td>\n",
       "      <td>sucks hear. hate days like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31176</th>\n",
       "      <td>Grrrr....I got the wrong size coat for the sheep</td>\n",
       "      <td>0</td>\n",
       "      <td>grrrr....i got wrong size coat sheep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31177</th>\n",
       "      <td>4 cases of swine flu!</td>\n",
       "      <td>1</td>\n",
       "      <td>4 cases swine flu!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31178</th>\n",
       "      <td>excellent</td>\n",
       "      <td>2</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31179</th>\n",
       "      <td>is sitting thru the boring bits in Titanic wai...</td>\n",
       "      <td>1</td>\n",
       "      <td>sitting thru boring bits titanic waiting good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31180</th>\n",
       "      <td>Missed the play</td>\n",
       "      <td>0</td>\n",
       "      <td>missed play</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31181 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target  \\\n",
       "0                        Cooking microwave pizzas, yummy       2   \n",
       "1      Any plans of allowing sub tasks to show up in ...       1   \n",
       "2       I love the humor, I just reworded it. Like sa...       2   \n",
       "3                           naw idk what ur talkin about       1   \n",
       "4              That sucks to hear. I hate days like that       0   \n",
       "...                                                  ...     ...   \n",
       "31176   Grrrr....I got the wrong size coat for the sheep       0   \n",
       "31177                              4 cases of swine flu!       1   \n",
       "31178                                          excellent       2   \n",
       "31179  is sitting thru the boring bits in Titanic wai...       1   \n",
       "31180                                    Missed the play       0   \n",
       "\n",
       "                                              clean_text  \n",
       "0                        cooking microwave pizzas, yummy  \n",
       "1                  plans allowing sub tasks show widget?  \n",
       "2      love humor, reworded it. like saying 'group th...  \n",
       "3                                      naw idk ur talkin  \n",
       "4                             sucks hear. hate days like  \n",
       "...                                                  ...  \n",
       "31176               grrrr....i got wrong size coat sheep  \n",
       "31177                                 4 cases swine flu!  \n",
       "31178                                          excellent  \n",
       "31179  sitting thru boring bits titanic waiting good ...  \n",
       "31180                                        missed play  \n",
       "\n",
       "[31181 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"az_train_review_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0728cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6660    0.6790    0.6724      1545\n",
      "           1     0.6123    0.6119    0.6121      1925\n",
      "           2     0.7457    0.7332    0.7394      1728\n",
      "\n",
      "    accuracy                         0.6722      5198\n",
      "   macro avg     0.6747    0.6747    0.6747      5198\n",
      "weighted avg     0.6726    0.6722    0.6724      5198\n",
      "\n",
      "Confusion matrix (test):\n",
      "[[1049  386  110]\n",
      " [ 425 1178  322]\n",
      " [ 101  360 1267]]\n",
      "Validation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6435    0.6957    0.6686      1515\n",
      "           1     0.6070    0.5991    0.6030      1923\n",
      "           2     0.7541    0.7120    0.7324      1757\n",
      "\n",
      "    accuracy                         0.6654      5195\n",
      "   macro avg     0.6682    0.6689    0.6680      5195\n",
      "weighted avg     0.6674    0.6654    0.6659      5195\n",
      "\n",
      "Confusion matrix (validation):\n",
      "[[1054  364   97]\n",
      " [ 460 1152  311]\n",
      " [ 124  382 1251]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "train_df = pd.read_csv(\"az_train_review_clean.csv\")\n",
    "test_df = pd.read_csv(\"az_test_review_clean.csv\")\n",
    "val_df = pd.read_csv(\"az_val_review_clean.csv\")\n",
    "\n",
    "X_train, y_train = train_df[\"clean_text\"], train_df[\"target\"]\n",
    "X_test, y_test = test_df[\"clean_text\"], test_df[\"target\"]\n",
    "X_val, y_val = val_df[\"clean_text\"], val_df[\"target\"]\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        ngram_range=(1,3),  # capture bigrams\n",
    "        min_df=5,\n",
    "        max_df=0.9,\n",
    "        sublinear_tf=True\n",
    "    )),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test report:\")\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(\"Confusion matrix (test):\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Validation report:\")\n",
    "y_val_pred = pipe.predict(X_val)\n",
    "print(classification_report(y_val, y_val_pred, digits=4))\n",
    "print(\"Confusion matrix (validation):\")\n",
    "print(confusion_matrix(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "311d184d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 31181\n",
      "test data: 5198\n",
      "Validation data: 5195\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data:\", X_train.shape[0])\n",
    "print(\"test data:\",X_test.shape[0])\n",
    "print(\"Validation data:\",X_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f6da780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "with open('pipe.pkl','wb')as f:\n",
    "    pk.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52c5a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
